BDEPEND=app-alternatives/ninja >=dev-build/cmake-3.20.5
DEFINED_PHASES=compile configure install prepare test
DEPEND=curl? ( net-misc/curl:= )
DESCRIPTION=Port of Facebook's LLaMA model in C/C++
EAPI=8
HOMEPAGE=https://github.com/ggerganov/llama.cpp
INHERIT=cmake
IUSE=curl
KEYWORDS=~amd64
LICENSE=MIT
RDEPEND=curl? ( net-misc/curl:= ) dev-python/numpy
SLOT=0
SRC_URI=https://github.com/ggerganov/llama.cpp/archive/refs/tags/b4576.tar.gz -> llama-cpp-0_pre4576.tar.gz
_eclasses_=toolchain-funcs	14648d8795f7779e11e1bc7cf08b7536	multilib	b2a329026f2e404e9e371097dda47f96	flag-o-matic	357f1a896fbedcd06e5ce55419c49eb9	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	xdg-utils	42869b3c8d86a70ef3cf75165a395e09	cmake	10a50dfaf728b802fcfd37f8d0da9056
_md5_=fa975210d09cd63984d1bb48b4112642
