BDEPEND=app-alternatives/ninja >=dev-build/cmake-3.20.5
DEFINED_PHASES=compile configure install prepare test
DEPEND=curl? ( net-misc/curl:= ) openblas? ( sci-libs/openblas:= ) blis? ( sci-libs/blis:= )
DESCRIPTION=Port of Facebook's LLaMA model in C/C++
EAPI=8
HOMEPAGE=https://github.com/ggerganov/llama.cpp
INHERIT=cmake
IUSE=curl openblas blis
KEYWORDS=~amd64
LICENSE=MIT
RDEPEND=curl? ( net-misc/curl:= ) openblas? ( sci-libs/openblas:= ) blis? ( sci-libs/blis:= ) dev-python/numpy
REQUIRED_USE=?? ( openblas blis )
SLOT=0
SRC_URI=https://github.com/ggerganov/llama.cpp/archive/refs/tags/b4576.tar.gz -> llama-cpp-0_pre4576.tar.gz
_eclasses_=toolchain-funcs	6afdb6107430c1832ca7e16aacbf8fa1	multilib	b2a329026f2e404e9e371097dda47f96	flag-o-matic	357f1a896fbedcd06e5ce55419c49eb9	multiprocessing	1e32df7deee68372153dca65f4a7c21f	ninja-utils	2df4e452cea39a9ec8fb543ce059f8d6	xdg-utils	42869b3c8d86a70ef3cf75165a395e09	cmake	10a50dfaf728b802fcfd37f8d0da9056
_md5_=75e526a55cb5da4c8e7df71acd19b37c
